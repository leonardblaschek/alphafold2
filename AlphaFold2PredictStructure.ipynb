{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/leonardblaschek/alphafold2/blob/master/AlphaFold2PredictStructure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4yBrceuFbf3"
   },
   "source": [
    "#Protein structure prediction with AlphaFold2 and MMseqs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGUBLzB3C6WN"
   },
   "source": [
    "Easy to use version of AlphaFold 2 (Jumper et al. 2021, Nature) using an API hosted at the Södinglab based on the MMseqs2 server (Mirdita et al. 2019, Bioinformatics) for the multiple sequence alignment creation. \n",
    "\n",
    "**Quickstart**\n",
    "1. Change the runtime type to GPU at \"Runtime\" -> \"Change runtime type\" (improves speed)\n",
    "2. Paste your protein sequence in the input field below\n",
    "3. Press \"Runtime\" -> \"Run all\"\n",
    "4. The pipeline has 8 steps. The currently running steps is indicated by a circle with a stop sign next to it. \n",
    "\n",
    "**Result**\n",
    "\n",
    "We produce two result files (1) a PDB formated structure and (2) a plot of the model quality. At the end of the computation a download modal box will pop with a `result.tar.gz` file.\n",
    "\n",
    "**Troubleshooting**\n",
    "* Try to restart the session \"Runntime\" -> \"Factory reset runtime\"\n",
    "* Check your input sequence \n",
    "\n",
    "**Limitations**\n",
    "* MSAs: MMseqs2 might not find as many hits compared to HHblits/HMMer searched against BFD and Mgnify.\n",
    "* Templates: Currently we do not use template information. But this is work in progress. \n",
    "* Computing resources: MMseqs2 can probably handle >20k requests per day since we run it only on 16 cores.\n",
    "\n",
    "For best results, we recommend using the full pipeline: https://github.com/deepmind/alphafold\n",
    "\n",
    "Most of the python code was written by Sergey Ovchinnikov (@sokrypton). The API is hosted at the Södinglab (@SoedingL) and maintained by Milot Mirdita (@milot_mirdita). Martin Steinegger (@thesteinegger) integrated everything.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "kOblAo-xetgx"
   },
   "outputs": [],
   "source": [
    "#@title Input protein sequence here before you \"Run all\"\n",
    "\n",
    "query_sequence = 'EVHFHEFVIQETPVKRLCRVHNSITVNGQFPGPTLEVRNGDSLVITAINKARYNISLHWHGIRQMRNPWADGPEYITQCPIQPGGSYTYRFTMEDQEGTLWWHAHSRWLRATVYGALIIRPPLSSPHYPFPVIPKREITLLLGEWWDRNPMDVLNLAQFTGAAPNISDAFTINGQPGDLYRCSSQETLRFLVGSGEIVLLRVINSALNQELFFGVANHKLTVVAADASYTKPFSTNVIMLGPGQTTDVLLTADQPPAHYYMAAHAYNSANAAFDNTTTTAILKYKDASCVTLQAKSQARAIPAQLPGFNDTATAAAFTAQMKSPSKVKVPLEIDENLFFTVGLGLFNCPTPNTQRCQGPNGTRFTASINNVSFVFPKQNSIMQAYYQGTPTGVFTTDFPPTPPVTFDYTGNVSRGLWQPTRGTKAYKLKFNSQVQIILQDTSIVTTENHPMHLHGYEFYVVGTGVGNFNPNTDTSSFNLIDPPRRNTIGTPPGGWVAIRFVANNPGAWLMHCHIDSHIFWGLAMVFLVENGEGHLQSVQSPPLDLPQC' #@param {type:\"string\"}\n",
    "# remove whitespaces\n",
    "query_sequence=\"\".join(query_sequence.split())\n",
    "jobname = 'AtLAC13' #@param {type:\"string\"}\n",
    "# remove whitespaces\n",
    "jobname=\"\".join(jobname.split())\n",
    "\n",
    "with open(f\"{jobname}.fasta\", \"w\") as text_file:\n",
    "    text_file.write(\">1\\n%s\" % query_sequence)\n",
    "\n",
    "# number of models to use\n",
    "#@markdown ---\n",
    "#@markdown ### Advanced settings\n",
    "num_models = 1 #@param [1,2,3,4,5] {type:\"raw\"}\n",
    "use_amber = True #@param {type:\"boolean\"}\n",
    "use_msa = True #@param {type:\"boolean\"}\n",
    "#@markdown ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iccGdbe_Pmt9",
    "outputId": "522daaee-0491-46f2-edf1-681e2a6159c9"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$use_amber\"\n",
    "cd /home/leonard/Applications/alphafold2/downloads\n",
    "if [ ! -f AF2_READY ]; then\n",
    "  # install dependencies\n",
    "  #apt-get -qq -y update 2>&1 1>/dev/null\n",
    "  #apt-get -qq -y install jq curl zlib1g gawk 2>&1 1>/dev/null\n",
    "  pip -q install biopython 2>&1 1>/dev/null\n",
    "  pip -q install dm-haiku 2>&1 1>/dev/null\n",
    "  pip -q install ml-collections 2>&1 1>/dev/null\n",
    "  pip -q install py3Dmol 2>&1 1>/dev/null\n",
    "  touch AF2_READY\n",
    "fi\n",
    "# download model\n",
    "if [ ! -d \"alphafold/\" ]; then\n",
    "  git clone https://github.com/deepmind/alphafold.git --quiet\n",
    "  mv alphafold alphafold_\n",
    "  mv alphafold_/alphafold .\n",
    "fi\n",
    "# download model params (~1 min)\n",
    "if [ ! -d \"params/\" ]; then\n",
    "  wget -qnc https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar\n",
    "  mkdir params\n",
    "  tar -xf alphafold_params_2021-07-14.tar -C params/\n",
    "  rm alphafold_params_2021-07-14.tar\n",
    "fi\n",
    "# install openmm for refinement\n",
    "if [ $1 == \"True\" ] && [ ! -f \"alphafold/common/stereo_chemical_props.txt\" ]; then\n",
    "  wget -qnc https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt\n",
    "  mv stereo_chemical_props.txt alphafold/common/\n",
    "  #wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "  #bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
    "  conda install -y -q -c conda-forge openmm=7.5.1 python=3.7 pdbfixer 2>&1 1>/dev/null\n",
    "  (cd /home/leonard/Applications/miniconda3/envs/alphafold/lib/python3.7/site-packages; patch -s -p0 < /home/leonard/Applications/alphafold2/downloads/alphafold_/docker/openmm.patch)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A9tUpDaikPC8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks done\n",
      "Found 2725 sequences (after redundacy filtering)\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$use_msa\" \"$jobname\"\n",
    "if [ $1 == \"True\" ]; then\n",
    "  if [ -f $2.result.tar.gz ]; then\n",
    "    echo \"looks done\"\n",
    "    tar xzf $2.result.tar.gz\n",
    "    tr -d '\\000' < uniref.a3m > $2.a3m\n",
    "  else\n",
    "    # build msa using the MMseqs2 search server\n",
    "    echo \"submitting job\"\n",
    "    ID=$(curl -s -F q=@$2.fasta -F mode=all https://a3m.mmseqs.com/ticket/msa | jq -r '.id')\n",
    "    STATUS=$(curl -s https://a3m.mmseqs.com/ticket/${ID} | jq -r '.status')\n",
    "    while [ \"${STATUS}\" == \"RUNNING\" ]; do\n",
    "        STATUS=$(curl -s https://a3m.mmseqs.com/ticket/${ID} | jq -r '.status')\n",
    "        sleep 1\n",
    "    done\n",
    "    if [ \"${STATUS}\" == \"COMPLETE\" ]; then\n",
    "        curl -s https://a3m.mmseqs.com/result/download/${ID}  > $2.result.tar.gz\n",
    "        tar xzf $2.result.tar.gz\n",
    "        tr -d '\\000' < uniref.a3m > $2.a3m\n",
    "    else\n",
    "        echo \"MMseqs2 server did not return a valid result.\"\n",
    "        exit 1\n",
    "    fi\n",
    "  fi\n",
    "  echo \"Found $(grep -c \">\" $2.a3m) sequences (after redundacy filtering)\"\n",
    "else\n",
    "  cp $2.fasta $2.a3m\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JPWfhGssZdTb"
   },
   "outputs": [],
   "source": [
    "#@title Setup model\n",
    "# the following code is written by Sergey Ovchinnikov\n",
    "# setup the model\n",
    "if \"model\" not in dir():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    import os\n",
    "    os.chdir('/home/leonard/Applications/alphafold2/downloads/')\n",
    "    import sys\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import py3Dmol\n",
    "    import matplotlib.pyplot as plt\n",
    "    from alphafold.common import protein\n",
    "    from alphafold.data import pipeline\n",
    "    from alphafold.data import templates\n",
    "    from alphafold.model import data\n",
    "    from alphafold.model import config\n",
    "    from alphafold.model import model\n",
    "\n",
    "    import ipywidgets\n",
    "    from ipywidgets import interact, fixed\n",
    "\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "if use_amber and \"relax\" not in dir():\n",
    "  sys.path.insert(0, '/home/leonard/Applications/miniconda3/envs/alphafold/lib/python3.7/site-packages/')\n",
    "  from alphafold.relax import relax\n",
    "\n",
    "if \"model_params\" not in dir(): model_params = {}\n",
    "for model_name in [\"model_1\",\"model_2\",\"model_3\",\"model_4\",\"model_5\"][:num_models]:\n",
    "  if model_name not in model_params:\n",
    "    model_config = config.model_config(model_name)\n",
    "    model_config.data.eval.num_ensemble = 1\n",
    "    model_params[model_name] = data.get_model_haiku_params(model_name=model_name, data_dir=\".\")\n",
    "    if model_name == \"model_1\":\n",
    "      model_runner_1 = model.RunModel(model_config, model_params[model_name])\n",
    "    if model_name == \"model_3\":\n",
    "      model_runner_3 = model.RunModel(model_config, model_params[model_name])\n",
    "\n",
    "def mk_mock_template(query_sequence):\n",
    "  # since alphafold's model requires a template input\n",
    "  # we create a blank example w/ zero input, confidence -1\n",
    "  ln = len(query_sequence)\n",
    "  output_templates_sequence = \"-\"*ln\n",
    "  output_confidence_scores = np.full(ln,-1)\n",
    "  templates_all_atom_positions = np.zeros((ln, templates.residue_constants.atom_type_num, 3))\n",
    "  templates_all_atom_masks = np.zeros((ln, templates.residue_constants.atom_type_num))\n",
    "  templates_aatype = templates.residue_constants.sequence_to_onehot(output_templates_sequence,\n",
    "                                                                    templates.residue_constants.HHBLITS_AA_TO_ID)\n",
    "  template_features = {'template_all_atom_positions': templates_all_atom_positions[None],\n",
    "                       'template_all_atom_masks': templates_all_atom_masks[None],\n",
    "                       'template_sequence': [f'none'.encode()],\n",
    "                       'template_aatype': np.array(templates_aatype)[None],\n",
    "                       'template_confidence_scores': output_confidence_scores[None],\n",
    "                       'template_domain_names': [f'none'.encode()],\n",
    "                       'template_release_date': [f'none'.encode()]}\n",
    "  return template_features\n",
    "\n",
    "def set_bfactor(pdb_filename, bfac):\n",
    "  I = open(pdb_filename,\"r\").readlines()\n",
    "  O = open(pdb_filename,\"w\")\n",
    "  for line in I:\n",
    "    if line[0:6] == \"ATOM  \":\n",
    "      seq_id = int(line[23:26].strip()) - 1\n",
    "      O.write(\"{prefix}{bfac:6.2f}{suffix}\".format(prefix=line[:60], bfac=bfac[seq_id], suffix=line[66:]))\n",
    "  O.close()\n",
    "\n",
    "def predict_structure(prefix, feature_dict, do_relax=True, random_seed=0):  \n",
    "  \"\"\"Predicts structure using AlphaFold for the given sequence.\"\"\"\n",
    "\n",
    "  # Run the models.\n",
    "  plddts = []\n",
    "  unrelaxed_pdb_lines = []\n",
    "  relaxed_pdb_lines = []\n",
    "\n",
    "  for model_name, params in model_params.items():\n",
    "    print(f\"running {model_name}\")\n",
    "    # swap params to avoid recompiling\n",
    "    # note: models 1,2 have diff number of params compared to models 3,4,5\n",
    "    if any(str(m) in model_name for m in [1,2]): model_runner = model_runner_1\n",
    "    if any(str(m) in model_name for m in [3,4,5]): model_runner = model_runner_3\n",
    "    model_runner.params = params\n",
    "    \n",
    "    processed_feature_dict = model_runner.process_features(feature_dict, random_seed=random_seed)\n",
    "    prediction_result = model_runner.predict(processed_feature_dict)\n",
    "    unrelaxed_protein = protein.from_prediction(processed_feature_dict,prediction_result)\n",
    "    unrelaxed_pdb_lines.append(protein.to_pdb(unrelaxed_protein))\n",
    "    plddts.append(prediction_result['plddt'])\n",
    "\n",
    "    if do_relax:\n",
    "      # Relax the prediction.\n",
    "      amber_relaxer = relax.AmberRelaxation(max_iterations=0,tolerance=2.39,\n",
    "                                            stiffness=10.0,exclude_residues=[],\n",
    "                                            max_outer_iterations=20)      \n",
    "      relaxed_pdb_str, _, _ = amber_relaxer.process(prot=unrelaxed_protein)\n",
    "      relaxed_pdb_lines.append(relaxed_pdb_str)\n",
    "\n",
    "  # rerank models based on predicted lddt\n",
    "  lddt_rank = np.mean(plddts,-1).argsort()[::-1]\n",
    "  plddts_ranked = {}\n",
    "  for n,r in enumerate(lddt_rank):\n",
    "    print(f\"model_{n+1} {np.mean(plddts[r])}\")\n",
    "\n",
    "    unrelaxed_pdb_path = f'{prefix}_unrelaxed_model_{n+1}.pdb'    \n",
    "    with open(unrelaxed_pdb_path, 'w') as f: f.write(unrelaxed_pdb_lines[r])\n",
    "    set_bfactor(unrelaxed_pdb_path,plddts[r]/100)\n",
    "\n",
    "    if do_relax:\n",
    "      relaxed_pdb_path = f'{prefix}_relaxed_model_{n+1}.pdb'\n",
    "      with open(relaxed_pdb_path, 'w') as f: f.write(relaxed_pdb_lines[r])\n",
    "      set_bfactor(relaxed_pdb_path,plddts[r]/100)\n",
    "\n",
    "    plddts_ranked[f\"model_{n+1}\"] = plddts[r]\n",
    "\n",
    "  return plddts_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hUYApPElB30u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model_1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuSolver internal error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-19e3165f42ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mmk_mock_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplddts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_relax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_amber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-6326adcbccf6>\u001b[0m in \u001b[0;36mpredict_structure\u001b[0;34m(prefix, feature_dict, do_relax, random_seed)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprocessed_feature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_feature_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0munrelaxed_protein\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_feature_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0munrelaxed_pdb_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelaxed_protein\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/alphafold2/downloads/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat)\u001b[0m\n\u001b[1;32m    132\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[1;32m    133\u001b[0m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;31m# This block is to ensure benchmark timings are accurate. Some blocking is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# already happening when computing get_confidence_metrics, and this ensures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "\u001b[0;32m~/Applications/miniconda3/envs/alphafold/lib/python3.7/site-packages/jaxlib/cusolver.py\u001b[0m in \u001b[0;36msyevd\u001b[0;34m(c, a, lower)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"cusolver_syevj\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     lwork, opaque = cusolver_kernels.build_syevj_descriptor(\n\u001b[0;32m--> 282\u001b[0;31m         np.dtype(dtype), lower, batch, n)\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"cusolver_syevd\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuSolver internal error"
     ]
    }
   ],
   "source": [
    "#@title Predict structure\n",
    "a3m_lines = \"\".join(open(f\"{jobname}.a3m\",\"r\").readlines())\n",
    "msa, deletion_matrix = pipeline.parsers.parse_a3m(a3m_lines)\n",
    "query_sequence = msa[0]\n",
    "feature_dict = {\n",
    "    **pipeline.make_sequence_features(sequence=query_sequence,\n",
    "                                      description=\"none\",\n",
    "                                      num_res=len(query_sequence)),\n",
    "    **pipeline.make_msa_features(msas=[msa],deletion_matrices=[deletion_matrix]),\n",
    "    **mk_mock_template(query_sequence)\n",
    "}\n",
    "plddts = predict_structure(jobname, feature_dict, do_relax=use_amber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exKwNxDxF7IO"
   },
   "outputs": [],
   "source": [
    "#@title Plot lDDT per residue\n",
    "# confidence per position\n",
    "plt.figure(dpi=100)\n",
    "for model_name,value in plddts.items():\n",
    "  plt.plot(value,label=model_name)\n",
    "plt.legend()\n",
    "plt.ylim(0,100)\n",
    "plt.ylabel(\"predicted lDDT\")\n",
    "plt.xlabel(\"positions\")\n",
    "plt.savefig(jobname+\"_lDDT.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xbvRNrwnJqj"
   },
   "outputs": [],
   "source": [
    "#@title Plot Number of Sequences per Position\n",
    "# confidence per position\n",
    "plt.figure(dpi=100)\n",
    "plt.plot((feature_dict[\"msa\"] != 21).sum(0))\n",
    "plt.xlabel(\"positions\")\n",
    "plt.ylabel(\"number of sequences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "g-rPnOXdjf18"
   },
   "outputs": [],
   "source": [
    "#@title Show 3D structure\n",
    "def show_pdb(model_name,\n",
    "             show_sidechains=False,\n",
    "             show_mainchain=False,\n",
    "             color=\"None\"):\n",
    "\n",
    "  def mainchain(p, color=\"white\", model=0):\n",
    "    BB = ['C','O','N','CA']\n",
    "    p.addStyle({\"model\":model,'atom':BB},\n",
    "                       {'stick':{'colorscheme':f\"{color}Carbon\",'radius':0.4}})\n",
    "\n",
    "  def sidechain(p, model=0):\n",
    "    HP = [\"ALA\",\"GLY\",\"VAL\",\"ILE\",\"LEU\",\"PHE\",\"MET\",\"PRO\",\"TRP\",\"CYS\",\"TYR\"]\n",
    "    BB = ['C','O','N']\n",
    "    p.addStyle({\"model\":model,'and':[{'resn':HP},{'atom':BB,'invert':True}]},\n",
    "              {'stick':{'colorscheme':\"yellowCarbon\",'radius':0.4}})\n",
    "    p.addStyle({\"model\":model,'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
    "              {'sphere':{'colorscheme':\"yellowCarbon\",'radius':0.4}})\n",
    "    p.addStyle({\"model\":model,'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
    "              {'stick':{'colorscheme':\"yellowCarbon\",'radius':0.4}})  \n",
    "    p.addStyle({\"model\":model,'and':[{'resn':HP,'invert':True},{'atom':BB,'invert':True}]},\n",
    "              {'stick':{'colorscheme':\"whiteCarbon\",'radius':0.4}})\n",
    "\n",
    "  if use_amber:\n",
    "    pdb_filename = f\"{jobname}_relaxed_{model_name}.pdb\"\n",
    "  else:\n",
    "    pdb_filename = f\"{jobname}_unrelaxed_{model_name}.pdb\"\n",
    "\n",
    "  p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
    "  p.addModel(open(pdb_filename,'r').read(),'pdb')\n",
    "  if color == \"lDDT\":\n",
    "    p.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0,'max':1}}})\n",
    "  elif color == \"rainbow\":\n",
    "    p.setStyle({'cartoon': {'color':'spectrum'}})\n",
    "  else:\n",
    "    p.setStyle({'cartoon':{}})\n",
    "\n",
    "  if show_sidechains: sidechain(p)\n",
    "  if show_mainchain: mainchain(p)\n",
    "  p.zoomTo()\n",
    "  return p.show()\n",
    "\n",
    "interact(show_pdb,\n",
    "         model_name=ipywidgets.Dropdown(options=model_params.keys(), value='model_1'),\n",
    "         show_sidechains=ipywidgets.Checkbox(value=False),\n",
    "         show_mainchain=ipywidgets.Checkbox(value=False),\n",
    "         color=ipywidgets.Dropdown(options=['None', 'rainbow', 'lDDT'], value='lDDT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "33g5IIegij5R"
   },
   "outputs": [],
   "source": [
    "#@title Download result\n",
    "!tar cfz $jobname\".result.tar.gz\" $jobname\"_\"*\"relaxed_model_\"*\".pdb\" $jobname\"_lDDT.png\"\n",
    "from google.colab import files\n",
    "files.download(f\"{jobname}.result.tar.gz\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "AlphaFold2PredictStructure.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
